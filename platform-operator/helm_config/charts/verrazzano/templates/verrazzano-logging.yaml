# Copyright (c) 2021, 2022, Oracle and/or its affiliates.
# Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl.

{{- if .Values.fluentd.enabled }}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Values.logging.name }}-init
  namespace: {{ .Release.Namespace }}
  labels:
    app: {{ .Values.logging.name }}
data:
  init.sh: |
    #!/bin/bash
    cat /etc/ssl/certs/ca-bundle.crt > /fluentd/cacerts/all-ca-certs.pem
    if [ -f "/fluentd/secret/ca-bundle" ]; then
      cat /fluentd/secret/ca-bundle >> /fluentd/cacerts/all-ca-certs.pem
    fi
    if [ -f "/fluentd/secret/es-ca-bundle" ]; then
      cat /fluentd/secret/es-ca-bundle >> /fluentd/cacerts/all-ca-certs.pem
    fi
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Values.logging.name }}-es-config
  namespace: {{ .Release.Namespace }}
  labels:
    app: {{ .Values.logging.name }}
data:
  {{- if .Values.logging.elasticsearchURL }}
  es-url: {{ .Values.logging.elasticsearchURL }}
  {{- else }}
  es-url: http://verrazzano-authproxy-elasticsearch:8775
  {{- end }}
  {{- if .Values.logging.elasticsearchSecret }}
  es-secret: {{ .Values.logging.elasticsearchSecret }}
  {{- else }}
  es-secret: verrazzano
  {{- end }}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Values.logging.name }}-config
  namespace: {{ .Release.Namespace }}
  labels:
    app: {{ .Values.logging.name }}
data:
  fluent.conf: |
    # Use the config specified by the FLUENTD_CONFIG environment variable, or
    # default to fluentd-standalone.conf
    @include "#{ENV['FLUENTD_CONFIG'] || 'fluentd-standalone.conf'}"

  # A config for running Fluentd as a daemon which collects, filters, parses,
  # and sends log to storage. No extra Fluentd processes required.
  fluentd-standalone.conf: |
    # Common config
    @include general.conf
    @include prometheus.conf

    # Input sources
    @include systemd-input.conf
    @include kubernetes-input.conf

    # Parsing/Filtering
    @include systemd-filter.conf
    @include kubernetes-filter.conf
    @include components-filter.conf

    # Send to storage
    @include output.conf
    {{- if .Values.fluentd.oci }}
    # Start namespace logging configs
    # End namespace logging configs
    {{- if .Values.fluentd.oci.systemLogId }}
    @include oci-logging-system.conf
    {{- if .Values.fluentd.oci.defaultAppLogId }}
    @include oci-logging-default-app.conf
    {{- end }}
    {{- end }}
    {{- else }}
    @include es-output.conf
    {{- end }}

  general.conf: |
    # Prevent Fluentd from handling records containing its own logs. Otherwise
    # it can lead to an infinite loop, when error in sending one message generates
    # another message which also fails to be sent and so on.
    <label @FLUENT_LOG>
      <match fluent.*>
        @type null
      </match>
    </label>

    # Used for health checking
    <source>
      @type http
      @id in_http
      port 9880
      bind 0.0.0.0
    </source>

    # Emits internal metrics to every minute, and also exposes them on port
    # 24220. Useful for determining if an output plugin is retrying/erroring,
    # or determining the buffer queue length.
    <source>
      @type monitor_agent
      @id in_monitor_agent
      bind 0.0.0.0
      port 24220
      tag fluentd.monitor.metrics
    </source>

  prometheus.conf: |
    # input plugin that is required to expose metrics by other Prometheus
    # plugins, such as the prometheus_monitor input below.
    <source>
      @type prometheus
      @id prometheus
      bind 0.0.0.0
      port 24231
      metrics_path /metrics
    </source>

    # input plugin that collects metrics from MonitorAgent and exposes them
    # as Prometheus metrics
    <source>
      @type prometheus_monitor
      @id prometheus_monitor
      # update the metrics every 20 seconds
      interval 20
    </source>

    <source>
      @type prometheus_output_monitor
      @id prometheus_output_monitor
      interval 20
    </source>

    <source>
      @type prometheus_tail_monitor
      @id prometheus_tail_monitor
      interval 20
    </source>

  systemd-input.conf: |
    <source>
      @type systemd
      @id in_systemd_run
      read_from_head true
      tag systemd
      path /run/log/journal
      <storage>
        @type local
        persistent true
        path /tmp/run_journald_pos.json
      </storage>
      <entry>
        fields_strip_underscores true
      </entry>
    </source>

  systemd-filter.conf: |
    <filter systemd>
       @type record_transformer
       @id systemd_index
       <record>
          target_index verrazzano-systemd-journal
       </record>
    </filter>

    <filter systemd.kubelet>
      @type parser
      @id systemd_kubelet_parser
      format kubernetes
      reserve_data true
      key_name MESSAGE
    </filter>

    <filter systemd.docker>
      @type parser
      @id systemd_docker_parser
      format /^time="(?<time>[^)]*)" level=(?<severity>[^ ]*) msg="(?<message>[^"]*)"( err="(?<error>[^"]*)")?( statusCode=($<status_code>\d+))?/
      reserve_data true
      key_name MESSAGE
    </filter>

    # Filter ssh logs since it's mostly bots trying to login
    <filter systemd.**>
      @type grep
      @id systemd_grep
      <exclude>
        key SYSTEMD_UNIT
        pattern (sshd@.*\.service)
      </exclude>
    </filter>

  kubernetes-input.conf: |
    # Capture Kubernetes pod logs
    # The kubelet creates symlinks that capture the pod name, namespace,
    # container name & Docker container ID to the docker logs for pods in the
    # /var/log/containers directory on the host.
    <source>
      @type tail
      # @id in_tail
      path /var/log/containers/*.log
      pos_file /tmp/fluentd-containers.log.pos
      # Exclude the log of the Fluentd daemonset itself
      exclude_path ["/var/log/containers/fluentd*_verrazzano-system_fluentd*.log"]
      tag kubernetes.*
      read_from_head true
      # @log_level debug
      <parse>
        @type multi_format
        <pattern>
          format json
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        # KIND CRI pattern/format
        <pattern>
          format /^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<flags>[^ ]+) (?<log>.*)$/
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        # OKE v1.20.8
        <pattern>
          format /^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<flags>[^ ]+) (?<log>.*)$/
          time_format %Y-%m-%dT%H:%M:%S.%N%:z
        </pattern>
      </parse>
    </source>

  components-filter.conf: |
    # filter to parse istio-proxy and istiod container log files
    <filter kubernetes.**istio-proxy** kubernetes.**istiod**istio-system_discovery**>
      @type parser
      @id istio
      key_name log
      reserve_data true
      emit_invalid_record_to_error true
      <parse>
        # istio containers have two formats for log records
        # one has a timestamp, log level and other fields
        # the other is just a messsage
        @type multi_format
        <pattern>
          format /^(?<logtime>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d{6}Z)\t(?<level>.*?)\t(?<message>[\s\S]*?)$/
          time_key logtime
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>

    # filter to parse authproxy container log files
    <filter kubernetes.**verrazzano-authproxy**verrazzano-authproxy**>
      @type parser
      @id authproxy
      key_name log
      reserve_data true
      emit_invalid_record_to_error true
      <parse>
        # authproxy has two formats for log records
        # one has a timestamp, log level and other fields
        # the other is just a messsage
        @type multi_format
        <pattern>
          format /^(?<logtime>\d{4}\/\d{2}\/\d{2} \d{2}\:\d{2}\:\d{2}) \[(?<level>.*?)\] (?<message>[\s\S]*?)$/
          time_key logtime
          time_format %Y/%m/%d %H:%M:%S
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>

    # filter to parse kiali container log files
    <filter kubernetes.**vmi-system-kiali**verrazzano-system_vmi-system-kiali**>
      @type parser
      @id vmi-system-kiali
      key_name log
      reserve_data true
      emit_invalid_record_to_error true
      <parse>
        # Kiali has two formats for log records
        # Kiali format and a klog format
        @type multi_format
        <pattern>
          format /^(?<logtime>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}Z) (?<level>.*?) (?<message>[\s\S]*?)$/
          time_key logtime
          time_format %Y-%m-%dT%H:%M:%SZ
        </pattern>
        <pattern>
          format /^(?<level>.)(\d{2}\d{2}) (?<logtime>\d{2}:\d{2}:\d{2}.\d{6})\s*?(?<message>[\s\S]*?)$/
          time_key logtime
          time_format %H:%M:%S.%N
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>

    # filter to parse Coherence operator container log files
    <filter kubernetes.**coherence-operator**verrazzano-system_manager**>
      @type parser
      @id coh-operator
      key_name log
      reserve_data true
      emit_invalid_record_to_error true
      <parse>
        # Coherence operator has two formats for log records
        # Coherence operator format and a klog format
        @type multi_format
        <pattern>
          format /^(?<logtime>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d{3}Z)\t(?<level>.*?)\t(?<message>[\s\S]*?)$/
          time_key logtime
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        <pattern>
          format /^(?<level>.)(\d{2}\d{2}) (?<logtime>\d{2}:\d{2}:\d{2}.\d{6})\s*?(?<message>[\s\S]*?)$/
          time_key logtime
          time_format %H:%M:%S.%N
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>

    # filter to parse oam-kubernetes-runtime container log files
    <filter kubernetes.**oam-kubernetes-runtime**verrazzano-system_oam-kubernetes-runtime**>
      @type parser
      @id oam-kubernetes-runtime
      key_name log
      reserve_data true
      emit_invalid_record_to_error true
      <parse>
        # oam-kubernetes-runtime has two formats for log records
        # oam-kubernetes-runtime format and a klog format
        @type multi_format
        <pattern>
          format /^(?<logtime>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d{3}Z)\t(?<level>.*?)\t(?<message>[\s\S]*?)$/
          time_key logtime
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        <pattern>
          format /^(?<level>.)(\d{2}\d{2}) (?<logtime>\d{2}:\d{2}:\d{2}.\d{6})\s*?(?<message>[\s\S]*?)$/
          time_key logtime
          time_format %H:%M:%S.%N
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>

    # filter to parse cert-manager container log files
    # includes cert-manager, ca-injector, webhook
    <filter kubernetes.**cert-manager**cert-manager**>
      @type parser
      @id cert-manager
      key_name log
      reserve_data true
      emit_invalid_record_to_error true
      <parse>
        # cert-manager has a klog format
        @type multi_format
        <pattern>
          format /^(?<level>.)(\d{2}\d{2}) (?<logtime>\d{2}:\d{2}:\d{2}.\d{6})\s*?(?<message>[\s\S]*?)$/
          time_key logtime
          time_format %H:%M:%S.%N
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>

    # filter to parse Verrazzano platform operator container log files
    <filter kubernetes.**verrazzano-**-operator** kubernetes.**verrazzano-**_webhook-init**>
      @type parser
      @id verrazzano-operators
      key_name log
      reserve_data true
      emit_invalid_record_to_error true
      <parse>
        @type multi_format
        <pattern>
          format json
          time_key @timestamp
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        # Kubernetes klog format
        <pattern>
          format /^(?<level>.)(\d{2}\d{2}) (?<logtime>\d{2}:\d{2}:\d{2}.\d{6})\s*?(?<message>[\s\S]*?)$/
          time_key logtime
          time_format %H:%M:%S.%N
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>
    
    # filter to parse Keycloak container log files
    <filter kubernetes.**keycloak**keycloak_keycloak**>
      @type parser
      @id keycloak
      key_name log
      reserve_data true
      emit_invalid_record_to_error true
      <parse>
        # Keycloak has one format for log records
        @type multi_format
        <pattern>
          format /^.*?(?<logtime>\d{2}:\d{2}:\d{2},\d{3}) (?<level>.*?)( |\t)+\[.*?\]( |\t)+\(.*?\)( |\t)+(?<message>.*)$/
          time_key logtime
          time_format %H:%M:%S,%N
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>
    
    # filter to parse MySQL container log files
    <filter kubernetes.**mysql**keycloak_mysql**>
      @type parser
      @id mysql
      key_name log
      reserve_data true
      emit_invalid_record_to_error true
      <parse>
        # MySQL has two formats for log records
        @type multi_format
        <pattern>
          format /^(?<logtime>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d{6}Z) \d+ \[(?<level>.*?)\] (\[.*?\] ){2}(?<message>.*?)$/
          time_key logtime
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        <pattern>
          format /^(?<logtime>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\+\d{2}:\d{2} \[(?<level>.*?)\] \[.*?\]: (?<message>.*?)$/
          time_key logtime
          time_format %Y-%m-%d %H:%M:%S
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>

    # filter to parse verrazzano-system prometheus container log files
    <filter kubernetes.**vmi-system-prometheus**verrazzano-system_prometheus**>
      @type parser
      @id vmi-system-prometheus
      key_name log
      reserve_data true
      emit_invalid_record_to_error true
      <parse>
        # Prometheus has two formats for log records
        # One with a level and msg
        # One with a level but not msg
        @type multi_format
        <pattern>
          format /^ts=(?<logtime>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d{3}Z)(.*)level=(?<level>.*?) (.*?)msg="(?<message>.*?)"([\s\S]*?)$/
          time_key logtime
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        <pattern>
          format /^ts=(?<logtime>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d{3}Z)(.*)level=(?<level>.*?) (?<message>[\s\S]*?)$/
          time_key logtime
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        # Kubernetes klog format
        <pattern>
          format /^(?<level>.)(\d{2}\d{2}) (?<logtime>\d{2}:\d{2}:\d{2}.\d{6})\s*?(?<message>[\s\S]*?)$/
          time_key logtime
          time_format %H:%M:%S.%N
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>

    # filter to parse verrazzano-system config-reloader container log files
    <filter kubernetes.**vmi-system-prometheus**verrazzano-system_config-reloader**>
      @type parser
      @id config-reloader
      key_name log
      reserve_data true
      emit_invalid_record_to_error true
      <parse>
        # config-reloader log messages do not have a log level
        @type multi_format
        <pattern>
          format /^(?<logtime>\d{4}\/\d{2}\/\d{2} \d{2}:\d{2}:\d{2}) (?<message>[\s\S]*?)$/
          time_key logtime
          time_format %Y/%m/%d %H:%M:%S
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>

  kubernetes-filter.conf: |
    # Query the API for extra metadata.
    <filter kubernetes.**>
      @type kubernetes_metadata
      @id kubernetes_metadata
      watch_retry_interval 20
    </filter>

    # rewrite_tag_filter does not support nested fields like
    # kubernetes.container_name, so this exists to flatten the fields
    # so we can use them in our rewrite_tag_filter
    <filter kubernetes.**>
      @type record_transformer
      @id kubernetes_record_transformer
      enable_ruby true
      <record>
        target_index verrazzano-namespace-${record["kubernetes"]["namespace_name"]}
      </record>
      <record>
        kubernetes_namespace_container_name ${record["kubernetes"]["namespace_name"]}.${record["kubernetes"]["container_name"]}
      </record>
    </filter>

    # parse sidecar stdout
    <filter kubernetes.**_fluentd-stdout-sidecar-**>
      @type parser
      @id stdout_log_text
      key_name log
      reserve_data true
      ignore_key_not_exist true
      emit_invalid_record_to_error true
      <parse>
         @type multi_format
         <pattern>
           format /^(?<time>[^ ]* [^ ]* [^ ]*) (?<flags>[^\s]+): (?<log>[\s\S]*)$/
         </pattern>
         <pattern>
            format none
         </pattern>
      </parse>
    </filter>

    # parse log record
    <filter kubernetes.**>
      @type parser
      @id parse_log_to_json
      key_name log
      reserve_data true
      ignore_key_not_exist true
      emit_invalid_record_to_error true
      <parse>
        @type multi_format
        <pattern>
          format json
          time_key @timestamp
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>

    # Remove the unnecessary field as the information is already available on
    # other fields.
    <filter kube.**>
      @type record_transformer
      @id kube_record_transformer
      remove_keys kubernetes_namespace_container_name
    </filter>

    <filter kube.kube-system.**>
      @type parser
      @id kube_parser
      format kubernetes
      reserve_data true
      key_name log
    </filter>

    <filter kube.**>
      @type parser
      key_name log
      reserve_data true
      remove_key_name_field false
      emit_invalid_record_to_error false
      <parse>
        @type multi_format
        <pattern>
          format json
          time_format %Y-%m-%dT%H:%M:%S.%N%Z
        </pattern>
        <pattern>
          format json
          time_format %Y-%m-%dT%H:%M:%S%z
        </pattern>
      </parse>
    </filter>

  output.conf: |
    <filter **>
      @type record_transformer
      @id cluster_name
      <record>
        cluster_name "#{ENV['CLUSTER_NAME']}"
      </record>
    </filter>

    # Force the timestamp field into ISO 8601 format
    <filter **>
      @type record_transformer
      @id time_format
      enable_ruby true
      <record>
        @timestamp ${time.iso8601(3)}
      </record>
    </filter>

  es-output.conf: |
    <match **>
      @type elasticsearch
      @id out_elasticsearch
      @log_level info
      log_es_400_reason true
      include_timestamp true
      target_index_key target_index
      index_name verrazzano-namespace-verrazzano-system
      include_tag_key true

      template_file /fluentd/etc/elasticsearch-template-verrazzano.json
      template_name elasticsearch-template-verrazzano.json
      template_overwrite true

      # time_as_integer needs to be set to false in order for Fluentd
      # to convert timestamps to Fluent::EventTime objects instead of
      # integers. Thus allowing Fluentd to preserve/transmit
      # nanosecond-precision values.
      time_as_integer false

      time_key timestamp

      # Prevent reloading connections to Elasticsearch
      reload_connections false
      reconnect_on_error true
      reload_on_failure true
      slow_flush_log_threshold 120s

      hosts "#{ENV['ELASTICSEARCH_URL']}"
      ca_file "#{ENV['CA_FILE']}"
      # ssl_version TLSv1_2
      user "#{ENV['ELASTICSEARCH_USER']}"
      password "#{ENV['ELASTICSEARCH_PASSWORD']}"
      bulk_message_request_threshold 16M
      suppress_type_name true
      type_name _doc
      # 2 ^ 31
      request_timeout 2147483648
      <buffer>
        @type file
        path /fluentd/log/elastic-buffer
        flush_thread_count 8
        flush_interval 5s
        retry_forever
        retry_max_interval 10
        # Cap buffer memory usage to 16MiB/chunk * 10 chunks = 160 MiB
        chunk_limit_size 16M
        queue_limit_length 10
        chunk_full_threshold 0.9
        overflow_action drop_oldest_chunk
      </buffer>
    </match>

{{- if .Values.fluentd.oci }}
  oci-logging-system.conf: |
    # Match all "system" namespaces so system log records are sent to a separate OCI Log object
    <match kubernetes.**kube-** kubernetes.**verrazzano-system** kubernetes.**verrazzano-install** kubernetes.**cattle-** kubernetes.**rancher-** kubernetes.**fleet-** kubernetes.**ingress-nginx** kubernetes.**istio-system** kubernetes.**keycloak** kubernetes.**cert-manager**  kubernetes.**_monitoring_** kubernetes.**_metallb-** kubernetes.**_local-path-storage_** systemd.** fluentd.monitor.metrics>
      @type oci_logging
      log_object_id {{ .Values.fluentd.oci.systemLogId }}
      <buffer>
        @type file
        path /fluentd/log/oci-logging-system
        disable_chunk_backup  true
        chunk_limit_size  5MB
        flush_interval  180s
        total_limit_size  1GB
        overflow_action  throw_exception
        retry_type  exponential_backoff
      </buffer>
    </match>

  oci-logging-default-app.conf: |
    <match **>
      @type oci_logging
      log_object_id {{ .Values.fluentd.oci.defaultAppLogId }}
      <buffer>
        @type file
        path /fluentd/log/oci-logging-default-app
        disable_chunk_backup  true
        chunk_limit_size  5MB
        flush_interval  180s
        total_limit_size  1GB
        overflow_action  throw_exception
        retry_type  exponential_backoff
      </buffer>
    </match>
{{- end }}

  elasticsearch-template-verrazzano.json: |
    {
      "index_patterns":"verrazzano-*",
      "version":60001,
      "settings":{
        "index.refresh_interval":"5s",
        "index.mapping.total_fields.limit":"2000",
        "number_of_shards":5,
        "index.number_of_replicas":0,
        "index.auto_expand_replicas":"0-1"
      },
      "mappings":{
        "dynamic_templates":[
          {
            "message_field":{
              "path_match":"message",
              "match_mapping_type":"string",
              "mapping":{
                "type":"text",
                "norms":false
              }
            }
          },
          {
            "string_fields":{
              "match":"*",
              "match_mapping_type":"string",
              "mapping":{
                "type":"text",
                "norms":false,
                "fields":{
                  "keyword":{
                    "type":"keyword",
                    "ignore_above":256
                  }
                }
              }
            }
          }
        ]
      }
    }
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{ .Values.logging.name }}
  namespace: {{ .Release.Namespace }}
  {{- if .Values.global.imagePullSecrets }}
imagePullSecrets:
  {{- range .Values.global.imagePullSecrets }}
- name: {{ . }}
  {{- end }}
  {{- end }}
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: {{ .Values.logging.name }}
rules:
  - apiGroups:
      - ""
    resources:
      - namespaces
      - pods
    verbs:
      - get
      - list
      - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: {{ .Values.logging.name }}
subjects:
  - kind: ServiceAccount
    name: {{ .Values.logging.name }}
    namespace: {{ .Release.Namespace }}
roleRef:
  kind: ClusterRole
  name: {{ .Values.logging.name }}
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: {{ .Values.logging.name }}
  namespace: {{ .Release.Namespace }}
  labels:
    app: fluentd
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      annotations:
        sidecar.istio.io/inject: "true"
      labels:
        app: fluentd
    spec:
      initContainers:
        - name: cacert-init
          command: ["/init/init.sh"]
          image: {{ .Values.logging.fluentdImage }}
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - mountPath: /init
              name: {{ .Values.logging.name }}-init
              readOnly: true
            - name: cacerts
              mountPath: /fluentd/cacerts
            - mountPath: /fluentd/secret
              name: secret-volume
              readOnly: true
      containers:
        - args:
            - -c
            - /etc/fluentd.conf
          env:
            - name: FLUENTD_CONF
              value: fluentd-standalone.conf
            - name: FLUENT_ELASTICSEARCH_SED_DISABLE
              value: "true"
            - name: ELASTICSEARCH_URL
  {{- if .Values.logging.elasticsearchURL }}
              value: {{ .Values.logging.elasticsearchURL }}
  {{- else }}
              value: http://verrazzano-authproxy-elasticsearch:8775
  {{- end }}
            - name: CLUSTER_NAME
              value: local
            - name: ELASTICSEARCH_USER
              valueFrom:
                secretKeyRef:
                  key: username
  {{- if .Values.logging.elasticsearchSecret }}
                  name: {{ .Values.logging.elasticsearchSecret }}
  {{- else }}
                  name: verrazzano
  {{- end }}
                  optional: true
            - name: ELASTICSEARCH_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: password
  {{- if .Values.logging.elasticsearchSecret }}
                  name: {{ .Values.logging.elasticsearchSecret }}
  {{- else }}
                  name: verrazzano
  {{- end }}
                  optional: true
            - name: CA_FILE
              value: /fluentd/cacerts/all-ca-certs.pem
          image: {{ .Values.logging.fluentdImage }}
          imagePullPolicy: IfNotPresent
          name: {{ .Values.logging.name }}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
            - name: cacerts
              mountPath: /fluentd/cacerts
            - mountPath: /fluentd/secret
              name: secret-volume
              readOnly: true
  {{- if .Values.fluentd.oci }}
  {{- if .Values.fluentd.oci.apiSecret }}
            - mountPath: /root/.oci
              name: oci-secret-volume
              readOnly: true
  {{- end }}
  {{- end }}
            - mountPath: /fluentd/etc
              name: {{ .Values.logging.name }}-config
              readOnly: true
            - mountPath: /var/log
              name: varlog
              readOnly: true
            - mountPath: /var/lib
              name: varlib
              readOnly: true
            - mountPath: /run/log/journal
              name: run-log-journal
              readOnly: true
{{- if .Values.fluentd.extraVolumeMounts }}
{{- range $i, $e := .Values.fluentd.extraVolumeMounts }}
            - mountPath: {{ $e.destination }}
              name: extra-volume-{{ $i }}
              readOnly: {{ $e.readOnly }}
{{- end }}
{{- end }}
      serviceAccount: fluentd
      serviceAccountName: fluentd
      terminationGracePeriodSeconds: 30
      volumes:
        - configMap:
            defaultMode: 0744
            name: {{ .Values.logging.name }}-init
          name: {{ .Values.logging.name }}-init
        - name: cacerts
          emptyDir: {}
        - name: secret-volume
          secret:
  {{- if .Values.logging.elasticsearchSecret }}
            secretName: {{ .Values.logging.elasticsearchSecret }}
  {{- else }}
            secretName: verrazzano
  {{- end }}
  {{- if .Values.fluentd.oci }}
  {{- if .Values.fluentd.oci.apiSecret }}
        - name: oci-secret-volume
          secret:
            secretName: {{ .Values.fluentd.oci.apiSecret }}
  {{- end }}
  {{- end }}
        - configMap:
            name: {{ .Values.logging.name }}-config
          name: {{ .Values.logging.name }}-config
        - hostPath:
            path: /var/log
            type: ""
          name: varlog
        - hostPath:
            path: /var/lib
            type: ""
          name: varlib
        - hostPath:
            path: /run/log/journal
            type: ""
          name: run-log-journal
{{- if .Values.fluentd.extraVolumeMounts }}
{{- range $i, $e := .Values.fluentd.extraVolumeMounts }}
        - hostPath:
            path: {{ $e.source }}
            type: ""
          name: extra-volume-{{ $i }}
{{- end }}
{{- end }}
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
{{- end }}

// Copyright (c) 2023, Oracle and/or its affiliates.
// Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl.

def DOCKER_IMAGE_TAG
def agentLabel = env.JOB_NAME.contains('master') ? "2.0-large-phx" : "2.0-large"
// def agentLabel = "largeexperimental"
def EFFECTIVE_DUMP_K8S_CLUSTER_ON_SUCCESS = false
def clusterSuffix = UUID.randomUUID().toString().substring(0,6).replace('-','')
def availableRegions = [  "us-ashburn-1", "ca-montreal-1", "ca-toronto-1", "eu-amsterdam-1", "eu-frankfurt-1", "eu-zurich-1", "uk-london-1" ]
Collections.shuffle(availableRegions)
def ocneK8sVersionSupport = [ "v1.25.7","v1.25.11","v1.26.6" ]
Collections.shuffle(ocneK8sVersionSupport)

pipeline {
    options {
        timeout(time: 2, unit: 'HOURS')
        skipDefaultCheckout true
        timestamps ()
    }

    agent {
       docker {
            image "${RUNNER_DOCKER_IMAGE}"
            args "${RUNNER_DOCKER_ARGS}"
            registryUrl "${RUNNER_DOCKER_REGISTRY_URL}"
            registryCredentialsId 'ocir-pull-and-push-account'
            label "${agentLabel}"
        }
    }

    parameters {
        choice (name: 'KUBERNETES_CLUSTER_VERSION',
                description: 'Kubernetes Version for Admin KinD Cluster',
                // 1st choice is the default value
                choices: [ "1.27", "1.26", "1.25", "1.24" ])
        choice (name: 'OCNE_KUBERNETES_CLUSTER_VERSION',
                        description: 'Kubernetes Version for OCNE Cluster',
                        // 1st choice is the default value
                        choices: ocneK8sVersionSupport)
        string (name: 'GIT_COMMIT_TO_USE',
                        defaultValue: 'NONE',
                        description: 'This is the full git commit hash from the source build to be used for all jobs',
                        trim: true)
        choice (description: 'OCI region to launch CAPI clusters in', name: 'CAPI_CLUSTER_REGION', choices: availableRegions )
        string (name: 'POD_CIDR',
                        defaultValue: '192.168.0.0/16',
                        description: 'POD cidr to be used in workload/managed OCNE cluster',
                        trim: true)
        string (name: 'CLUSTER_CIDR',
                defaultValue: '10.128.0.0/12',
                description: 'POD CLUSTER_CIDR to be used in workload/managed OCNE cluster',
                trim: true)
        string (name: 'OCNE_IMAGE_REPOSITORY',
                defaultValue: 'container-registry.oracle.com',
                description: 'OCNE registry value. Default container-registry.oracle.com',
                trim: true)
        string (name: 'OCNE_IMAGE_PATH',
                defaultValue: 'olcne',
                description: 'Path in OCNE registry value. Default olcne',
                trim: true)
        choice (description: 'Number of OCNE control plane nodes', name: 'CONTROL_PLANE_MACHINE_COUNT', choices: ["1", "3"])
        choice (description: 'Number of OCNE worker nodes', name: 'NODE_MACHINE_COUNT', choices: ["2","1","3"])
        string (name: 'NODE_OCPU',defaultValue: '4',description: 'Number of OCPUs for worker nodes with shape VM.Standard.E4.Flex',trim: true)
        string (name: 'MEMORY_GBS',defaultValue: '80',description: 'Amount of memory assigned to nodes with shape VM.Standard.E4.Flex',trim: true)
        string (name: 'ORACLE_LINUX_NAME',defaultValue: 'Oracle-Linux-8',description: 'Oracle Linux Display Name',trim: true)
        string (name: 'OPERATING_SYSTEM',defaultValue: 'Oracle Linux',description: 'Operating system filter used to fetch stock images',trim: true)
        string (name: 'OPERATING_SYSTEM_VERSION',defaultValue: '8',description: 'Version of Operating system to fetch',trim: true)

        string (name: 'VERRAZZANO_OPERATOR_IMAGE',
                                defaultValue: 'NONE',
                                description: 'Verrazzano platform operator image name (in ghcr.io repo).  If not specified, the operator.yaml from Verrazzano repo will be used to create Verrazzano platform operator',
                                trim: true)
        choice (name: 'WILDCARD_DNS_DOMAIN',description: 'This is the wildcard DNS domain',choices: [ "nip.io", "sslip.io"])
        choice (name: 'CRD_API_VERSION', description: 'This is the API crd version.', choices: [ "v1beta1", "v1alpha1"])
        booleanParam (description: 'Whether to create the cluster with Calico for AT testing (defaults to true)', name: 'CREATE_CLUSTER_USE_CALICO', defaultValue: true)
        booleanParam (description: 'Whether to dump k8s cluster on success (off by default can be useful to capture for comparing to failed cluster)', name: 'DUMP_K8S_CLUSTER_ON_SUCCESS', defaultValue: false)
        booleanParam (description: 'Whether to use a database for Grafana persistence', name: 'USE_DB_FOR_GRAFANA', defaultValue: false)
        string (name: 'CONSOLE_REPO_BRANCH', defaultValue: '',description: 'The branch to check out after cloning the console repository.',trim: true)
        booleanParam (description: 'Whether to enable debug logging of the istio envoy in the VZ API pod', name: 'ENABLE_API_ENVOY_LOGGING', defaultValue: true)
        string (name: 'TAGGED_TESTS',defaultValue: '',description: 'A comma separated list of build tags for tests that should be executed (e.g. unstable_test). Default:',trim: true)
        string (name: 'INCLUDED_TESTS', defaultValue: '.*', description: 'A regex matching any fully qualified test file that should be executed (e.g. examples/helidon/). Default: .*',trim: true)
        string (name: 'EXCLUDED_TESTS', defaultValue: '_excluded_test',description: 'A regex matching any fully qualified test file that should not be executed (e.g. multicluster/|_excluded_test). Default: _excluded_test',trim: true)
        string (name: 'INSTALL_PROFILE',defaultValue: 'dev', description: 'Verrazzano install profile (prod/dev) on admin cluster. default: dev',trim: true)
        booleanParam (description: 'Whether to capture full cluster snapshot on test failure', name: 'CAPTURE_FULL_CLUSTER', defaultValue: false)
        booleanParam (description: 'Whether to run Post-install Verify Tests on workload cluster', name: 'RUN_POST_INSTALL_VERIFY_TESTS', defaultValue: true)
        booleanParam (description: 'Whether to run Post-install Infra Tests on workload cluster.', name: 'RUN_POST_INSTALL_INFRA_TESTS', defaultValue: false)
        booleanParam (description: 'Whether to run Post-install Acceptance Tests on workload cluster.', name: 'RUN_POST_INSTALL_ACCEPTANCE_TESTS', defaultValue: false)
    }

    environment {
        DOCKER_PLATFORM_CI_IMAGE_NAME = 'verrazzano-platform-operator-jenkins'
        DOCKER_PLATFORM_PUBLISH_IMAGE_NAME = 'verrazzano-platform-operator'
        GOPATH = '/home/opc/go'
        GO_REPO_PATH = "${GOPATH}/src/github.com/verrazzano"
        DOCKER_CREDS = credentials('github-packages-credentials-rw')
        DOCKER_EMAIL = credentials('github-packages-email')
        DOCKER_REPO = 'ghcr.io'
        DOCKER_NAMESPACE = 'verrazzano'
        NETRC_FILE = credentials('netrc')
        POST_DUMP_FAILED_FILE = "${WORKSPACE}/post_dump_failed_file.tmp"
        TESTS_EXECUTED_FILE = "${WORKSPACE}/tests_executed_file.tmp"
        KUBECONFIG = "${WORKSPACE}/test_kubeconfig"
        VERRAZZANO_KUBECONFIG = "${KUBECONFIG}"
        OCR_CREDS = credentials('ocr-pull-and-push-account')
        OCR_REPO = 'container-registry.oracle.com'
        GITHUB_PKGS_CREDS = credentials('github-packages-credentials-rw')
        GHCR_REPO = 'ghcr.io'
        IMAGE_PULL_SECRET = 'verrazzano-container-registry'
        INSTALL_CONFIG_FILE_KIND = "./tests/e2e/config/scripts/${params.CRD_API_VERSION}/install-verrazzano-kind.yaml"
        TEST_OVERRIDE_CONFIGMAP_FILE = "./tests/e2e/config/scripts/pre-install-overrides/test-overrides-configmap.yaml"
        TEST_OVERRIDE_SECRET_FILE = "./tests/e2e/config/scripts/pre-install-overrides/test-overrides-secret.yaml"
        VZ_CLUSTERRESOURCESET_FILE = "./tests/e2e/clusterapi/capi/templates/cluster-template-verrazzano-resource.yaml"
        INSTALL_PROFILE = "${params.INSTALL_PROFILE}"
        KIND_NODE_COUNT = "3"
        VZ_ENVIRONMENT_NAME = "default"
        TEST_SCRIPTS_DIR = "${GO_REPO_PATH}/verrazzano/tests/e2e/config/scripts"
        VERRAZZANO_OPERATOR_IMAGE="${params.VERRAZZANO_OPERATOR_IMAGE}"

        WEBLOGIC_PSW = credentials('weblogic-example-domain-password') // required by WebLogic application and console ingress test
        DATABASE_PSW = credentials('todo-mysql-password') // required by console ingress test

        // Environment variables required to capture cluster snapshot and bug report on test failure
        DUMP_KUBECONFIG="${KUBECONFIG}"
        DUMP_COMMAND="${GO_REPO_PATH}/verrazzano/tools/scripts/k8s-dump-cluster.sh"
        TEST_DUMP_ROOT="${WORKSPACE}/test-cluster-snapshots"
        CAPTURE_FULL_CLUSTER="${params.CAPTURE_FULL_CLUSTER}"

        // Environment variable for Verrazzano CLI executable
        VZ_COMMAND="${GO_REPO_PATH}/vz"

        VERRAZZANO_INSTALL_LOGS_DIR="${WORKSPACE}/verrazzano/platform-operator/scripts/install/build/logs"
        VERRAZZANO_INSTALL_LOG="verrazzano-install.log"

        // used for console artifact capture on failure
        JENKINS_READ = credentials('jenkins-auditor')
        // OCI_CLI_AUTH="instance_principal"
        OCI_OS_NAMESPACE = credentials('oci-os-namespace')
        OCI_OS_ARTIFACT_BUCKET="build-failure-artifacts"
        OCI_OS_COMMIT_BUCKET="verrazzano-builds-by-commit"
        VZ_CLI_TARGZ="vz-linux-amd64.tar.gz"

        // used to emit metrics
        PROMETHEUS_CREDENTIALS = credentials('prometheus-credentials')
        TEST_ENV_LABEL = "magicdns_ocne"
        TEST_ENV = "OCNE"
        K8S_VERSION_LABEL = "${params.KUBERNETES_CLUSTER_VERSION}"
        SEARCH_HTTP_ENDPOINT = credentials('search-gw-url')
        SEARCH_PASSWORD = "${PROMETHEUS_CREDENTIALS_PSW}"
        SEARCH_USERNAME = "${PROMETHEUS_CREDENTIALS_USR}"

        // used to generate Ginkgo test reports
        TEST_REPORT = "test-report.xml"
        GINKGO_REPORT_ARGS = "--junit-report=${TEST_REPORT} --keep-separate-reports=true"
        TEST_REPORT_DIR = "${WORKSPACE}/tests/e2e"

        //OCI parameters
        OCI_CLI_TENANCY = credentials('oci-tenancy')
        OCI_CLI_USER = credentials('oci-user-ocid')
        OCI_CLI_FINGERPRINT = credentials('oci-api-key-fingerprint')
        OCI_CLI_KEY_FILE = credentials('oci-api-key')

        // TF parameters
        TF_VAR_compartment_id = credentials('oci-tiburon-dev-compartment-ocid')
        TF_VAR_tenancy_id = credentials('oci-tenancy')
        TF_VAR_tenancy_name = credentials('oci-tenancy-name')
        TF_VAR_user_id = credentials('oci-user-ocid')
        TF_VAR_region = "${params.CAPI_CLUSTER_REGION}"
        TF_VAR_kubernetes_version = "${params.OKE_CLUSTER_VERSION}"
        TF_VAR_nodepool_config = "${params.OKE_NODE_POOL}"
        TF_VAR_api_fingerprint = credentials('oci-api-key-fingerprint')
        TF_VAR_api_private_key_path = credentials('oci-api-key')
        TF_VAR_s3_bucket_access_key = credentials('oci-s3-bucket-access-key')
        TF_VAR_s3_bucket_secret_key = credentials('oci-s3-bucket-secret-key')
        TF_VAR_ssh_public_key_path = credentials('oci-tf-pub-ssh-key')

        // CAPI variables
        OCI_USER_ID = credentials('oci-user-ocid')
        OCI_CREDENTIALS_FINGERPRINT = credentials('oci-api-key-fingerprint')
        OCI_TENANCY_ID = credentials('oci-tenancy')
        OCI_REGION = "${params.CAPI_CLUSTER_REGION}"
        OCI_COMPARTMENT_ID = credentials('oci-tiburon-dev-compartment-ocid')

        POD_CIDR = "${params.POD_CIDR}"
        CLUSTER_CIDR = "${params.CLUSTER_CIDR}"
        OCNE_IMAGE_REPOSITORY = "${params.OCNE_IMAGE_REPOSITORY}"
        OCNE_IMAGE_PATH = "${params.OCNE_IMAGE_PATH}"
        KUBERNETES_VERSION = "${params.OCNE_KUBERNETES_CLUSTER_VERSION}"
        CLUSTER_SUFFIX_ID = "${clusterSuffix}"
        CLUSTER_NAMESPACE = "ocnecapikluster-${CLUSTER_SUFFIX_ID}"
        CLUSTER_NAME = "ocnecapikluster-${CLUSTER_SUFFIX_ID}"
        CAPI_NODE_SSH_KEY_PATH = credentials('oci-tf-pub-ssh-key')
        CAPI_OCI_PRIVATE_KEY_PATH = credentials('oci-api-key')
        ORACLE_LINUX_NAME = "${params.ORACLE_LINUX_NAME}"
        OPERATING_SYSTEM = "${params.OPERATING_SYSTEM}"
        OPERATING_SYSTEM_VERSION = "${params.OPERATING_SYSTEM_VERSION}"
        OCI_NODE_MACHINE_TYPE_OCPUS = "${params.NODE_OCPU}"
        OCI_NODE_MACHINE_MEMORY_GBS = "${params.MEMORY_GBS}"
    }

    stages {
        stage('Clean workspace and checkout') {
            steps {
                sh """
                    echo "${NODE_LABELS}"
                """

                script {
                    EFFECTIVE_DUMP_K8S_CLUSTER_ON_SUCCESS = getEffectiveDumpOnSuccess()
                    if (params.GIT_COMMIT_TO_USE == "NONE") {
                        echo "Specific GIT commit was not specified, use current head"
                        def scmInfo = checkout scm
                        env.GIT_COMMIT = scmInfo.GIT_COMMIT
                        env.GIT_BRANCH = scmInfo.GIT_BRANCH
                    } else {
                        echo "SCM checkout of ${params.GIT_COMMIT_TO_USE}"
                        def scmInfo = checkout([
                            $class: 'GitSCM',
                            branches: [[name: params.GIT_COMMIT_TO_USE]],
                            doGenerateSubmoduleConfigurations: false,
                            extensions: [],
                            submoduleCfg: [],
                            userRemoteConfigs: [[url: env.SCM_VERRAZZANO_GIT_URL]]])
                        env.GIT_COMMIT = scmInfo.GIT_COMMIT
                        env.GIT_BRANCH = scmInfo.GIT_BRANCH
                        // If the commit we were handed is not what the SCM says we are using, fail
                        if (!env.GIT_COMMIT.equals(params.GIT_COMMIT_TO_USE)) {
                            echo "SCM didn't checkout the commit we expected. Expected: ${params.GIT_COMMIT_TO_USE}, Found: ${scmInfo.GIT_COMMIT}"
                            exit 1
                        }
                    }
                    echo "SCM checkout of ${env.GIT_BRANCH} at ${env.GIT_COMMIT}"
                }

                sh """
                    cp -f "${NETRC_FILE}" $HOME/.netrc
                    chmod 600 $HOME/.netrc
                """

                script {
                    try {
                    sh """
                        echo "${DOCKER_CREDS_PSW}" | docker login ${env.DOCKER_REPO} -u ${DOCKER_CREDS_USR} --password-stdin
                    """
                    } catch(error) {
                        echo "docker login failed, retrying after sleep"
                        retry(4) {
                            sleep(30)
                            sh """
                                echo "${DOCKER_CREDS_PSW}" | docker login ${env.DOCKER_REPO} -u ${DOCKER_CREDS_USR} --password-stdin
                            """
                        }
                    }
                }
                sh """
                    rm -rf ${GO_REPO_PATH}/verrazzano
                    mkdir -p ${GO_REPO_PATH}/verrazzano
                    tar cf - . | (cd ${GO_REPO_PATH}/verrazzano/ ; tar xf -)
                """

                script {
                    def props = readProperties file: '.verrazzano-development-version'
                    VERRAZZANO_DEV_VERSION = props['verrazzano-development-version']
                    TIMESTAMP = sh(returnStdout: true, script: "date +%Y%m%d%H%M%S").trim()
                    SHORT_COMMIT_HASH = sh(returnStdout: true, script: "git rev-parse --short=8 HEAD").trim()
                    DOCKER_IMAGE_TAG = "${VERRAZZANO_DEV_VERSION}-${TIMESTAMP}-${SHORT_COMMIT_HASH}"
                    // update the description with some meaningful info
                    setDisplayName()
                    currentBuild.description = params.KUBERNETES_CLUSTER_VERSION + " : " + SHORT_COMMIT_HASH + " : " + env.GIT_COMMIT + " : " + params.GIT_COMMIT_TO_USE
                    def RUNNER_REGION = sh(returnStdout: true, script: "curl -s -H \"Authorization: Bearer Oracle\" http://169.254.169.254/opc/v2/instance/canonicalRegionName").trim()
                    println("runner region is ${RUNNER_REGION}, OCI CAPI region is ${env.OCI_REGION}, CAPI Cluster Name is ${env.CLUSTER_NAME}")
                }
                script {
                    sh """
                        echo "Downloading VZ CLI from object storage"
                        oci --region us-phoenix-1 os object get --namespace ${OCI_OS_NAMESPACE} -bn ${OCI_OS_COMMIT_BUCKET} --name ephemeral/${env.BRANCH_NAME}/${SHORT_COMMIT_HASH}/${VZ_CLI_TARGZ} --file ${VZ_CLI_TARGZ}
                        tar xzf ${VZ_CLI_TARGZ} -C ${GO_REPO_PATH}
                        ${GO_REPO_PATH}/vz version
                    """
                }
            }
        }

        stage('Acceptance Tests on OCNE cluster') {
            stages {

                stage('Prepare KinD environment as admin cluster') {
                    environment {
                        KIND_KUBERNETES_CLUSTER_VERSION="${params.KUBERNETES_CLUSTER_VERSION}"
                        OCI_OS_LOCATION="ephemeral/${env.BRANCH_NAME}/${SHORT_COMMIT_HASH}"
                        REALM_USER_PASSWORD = credentials('todo-mysql-password')
                        REALM_NAME = "test-realm"
                    }
                    steps {
                         script {
                            def RUNNER_REGION = sh(returnStdout: true, script: "curl -s -H \"Authorization: Bearer Oracle\" http://169.254.169.254/opc/v2/instance/canonicalRegionName").trim()
                            println("runner region is ${RUNNER_REGION}, OCI CAPI region is ${env.OCI_REGION}, CAPI Cluster Name is ${env.CLUSTER_NAME}")
                        }
                        sh """
                            cd ${GO_REPO_PATH}/verrazzano
                            ci/scripts/prepare_jenkins_at_environment.sh ${params.CREATE_CLUSTER_USE_CALICO} ${params.WILDCARD_DNS_DOMAIN} ${params.USE_DB_FOR_GRAFANA}
                        """
                    }
                    post {
                        failure {
                            archiveArtifacts artifacts: "**/kind-logs/**", allowEmptyArchive: true
                        }
                        always {
                            archiveArtifacts artifacts: "acceptance-test-operator.yaml,downloaded-operator.yaml,$INSTALL_CONFIG_FILE_KIND", allowEmptyArchive: true
                            // enable debug logging of Verrazzano api istio proxy
                            script {
                                if (params.ENABLE_API_ENVOY_LOGGING) {
                                    sh '''
                                        vz_api_pod=\$(kubectl get pod -n verrazzano-system -l app=verrazzano-authproxy --no-headers -o custom-columns=\":metadata.name\")
                                        if [ -z "\$vz_api_pod" ]; then
                                          echo "Could not find verrazzano-authproxy pod, not enabling debug logging"
                                        else
                                          kubectl exec \$vz_api_pod -c istio-proxy -n verrazzano-system -- curl -X POST http://localhost:15000/logging?level=debug
                                        fi
                                        nginx_ing_pod=\$(kubectl get pod -n verrazzano-ingress-nginx -l app.kubernetes.io/component=controller --no-headers -o custom-columns=\":metadata.name\")
                                        if [ -z "\$nginx_ing_pod" ]; then
                                          echo "Could not find nginx ingress controller pod, not enabling debug logging"
                                        else
                                          kubectl exec \$nginx_ing_pod -c istio-proxy -n verrazzano-ingress-nginx -- curl -X POST http://localhost:15000/logging?level=debug
                                        fi
                                    '''
                                }
                            }
                        }
                    }
                }

                stage('Verify-install on admin cluster') {
                    steps {
                        catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
                            sh """
                                cd ${WORKSPACE}/tests/e2e
                                ginkgo -p --randomize-all -v --keep-going --no-color ${GINKGO_REPORT_ARGS} -tags="${params.TAGGED_TESTS}" --focus-file="${params.INCLUDED_TESTS}" --skip-file="${params.EXCLUDED_TESTS}" verify-install/...
                            """
                        }
                    }
                    post {
                        always {
                            archiveArtifacts artifacts: '**/coverage.html,**/logs/*,**/test-cluster-dumps/**', allowEmptyArchive: true
                            junit testResults: '**/*test-result.xml', allowEmptyResults: true
                        }
                        failure {
                            script {
                                dumpK8sCluster('verify-install-admin-failure-dump')
                            }
                        }
                    }
                }

                stage('Display Verrazzano config to be deployed on workload cluster') {
                    steps {
                        catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
                            sh """
                                yq eval '. | select (.apiVersion == "v1") | .data."verrazzano.yaml"' ${VZ_CLUSTERRESOURCESET_FILE}
                            """
                        }
                    }
                }


                stage('Deploy OCNE workload cluster using CAPI and install Verrazzano') {
                    steps {
                        catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
                            script {
                                // This will deploy an OCNE cluster
                                // Then proceed to create image pull secrets required for jenkins
                                // Also deploy Verrazzano
                                set_capi_variables()
                                runGinkgo('clusterapi/capi')
                            }
                        }
                    }
                    post {
                        always {
                            archiveArtifacts artifacts: '**/coverage.html,**/logs/*,**/test-cluster-dumps/**', allowEmptyArchive: true
                            junit testResults: '**/*test-result.xml', allowEmptyResults: true
                        }
                        failure {
                            script {
                                dumpK8sCluster('ocne-deploy-failure')
                            }
                        }
                    }
                }

                stage('Display CAPI cluster conditions post VZ install on workload cluster') {
                    steps {
                        catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
                            sh """
                                clusterctl describe cluster -n ${CLUSTER_NAMESPACE} ${CLUSTER_NAMESPACE} --grouping=false --echo --show-conditions all --show-templates --show-resourcesets  --show-machinesets
                            """
                        }
                    }
                }

                stage('Post-install Verify Tests on workload cluster') {
                       when {
                           expression {params.RUN_POST_INSTALL_VERIFY_TESTS == true}
                       }
                       steps {
                           script {
                               parallel generateVerifyInstallStages("${TEST_DUMP_ROOT}/post-install-verify-tests")
                           }
                       }
                       post {
                           always {
                               archiveArtifacts artifacts: '**/coverage.html,**/logs/*,**/test-cluster-snapshots/**', allowEmptyArchive: true
                               junit testResults: '**/*test-result.xml', allowEmptyResults: true
                           }
                       }
               }

               stage('Post-install Infra Tests on workload cluster') {
                    when {
                        expression {params.RUN_POST_INSTALL_INFRA_TESTS == true}
                    }
                    steps {
                        script {
                            parallel generateVerifyInfraStages("${TEST_DUMP_ROOT}/post-install-infra-tests")
                        }
                    }
                    post {
                        always {
                            archiveArtifacts artifacts: '**/coverage.html,**/logs/*,**/test-cluster-snapshots/**', allowEmptyArchive: true
                            junit testResults: '**/*test-result.xml', allowEmptyResults: true
                        }
                    }
                }

               stage('Post-install Acceptance Tests on workload cluster') {
                    when {
                        expression {params.RUN_POST_INSTALL_ACCEPTANCE_TESTS == true}
                    }
                    steps {
                        script {
                            parallel generateAllAcceptanceTestStages("${TEST_DUMP_ROOT}/post-install-acceptance-tests", 'false', 'false')
                        }
                    }
                    post {
                        always {
                            archiveArtifacts artifacts: '**/coverage.html,**/logs/*,**/test-cluster-snapshots/**', allowEmptyArchive: true
                            junit testResults: '**/*test-result.xml', allowEmptyResults: true
                        }
                    }
               }

               stage('Uninstall vz from workload cluster') {
                    steps {
                        catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
                            sh """
                                TS=\$(date +%Y%m%d%H%M%S%N)
                                TEMPKUBECONFIGPATH=/tmp/${CLUSTER_NAME}-kubeconfig-\$TS
                                kubectl get secret -n ${CLUSTER_NAME} ${CLUSTER_NAME}-kubeconfig -o json | jq -r '.data.value' | base64 -d > \$TEMPKUBECONFIGPATH
                                kubectl --kubeconfig \$TEMPKUBECONFIGPATH get nodes -o wide
                                kubectl --kubeconfig \$TEMPKUBECONFIGPATH get pods -A
                                ${GO_REPO_PATH}/vz --kubeconfig \$TEMPKUBECONFIGPATH uninstall -y --timeout 60m
                                rm -rf \$TEMPKUBECONFIGPATH
                            """
                        }
                    }

               }

            }

        }

    }

    post {
        always {
            script {
                if ( fileExists(env.TESTS_EXECUTED_FILE) ) {
                    dumpVerrazzanoSystemPods()
                    dumpCattleSystemPods()
                    dumpNginxIngressControllerLogs()
                    dumpVerrazzanoPlatformOperatorLogs()
                    dumpVerrazzanoApplicationOperatorLogs()
                    dumpOamKubernetesRuntimeLogs()
                    dumpVerrazzanoApiLogs()
                    dumpCAPIPODLogs()
                    dumpCAPIClusterDetails()
                }
            }

            sh """
                # Copy the generated test reports to WORKSPACE to archive them
                mkdir -p ${TEST_REPORT_DIR}
                cd ${GO_REPO_PATH}/verrazzano/tests/e2e
                find . -name "${TEST_REPORT}" | cpio -pdm ${TEST_REPORT_DIR}
            """
            archiveArtifacts artifacts: "**/coverage.html,**/logs/**,**/verrazzano_images.txt,**/*full-cluster*/**,**/bug-report/**,**/Screenshot*.png,**/ConsoleLog*.log,**/${TEST_REPORT}", allowEmptyArchive: true
            junit testResults: "**/${TEST_REPORT}", allowEmptyResults: true
            ensureVZCleanupFromWorkloadCluster()
            ensureCAPICleanup()
            deleteCluster()
        }
        failure {
            sh """
                curl -k -u ${JENKINS_READ_USR}:${JENKINS_READ_PSW} -o ${WORKSPACE}/build-console-output.log ${BUILD_URL}consoleText
            """
            archiveArtifacts artifacts: '**/build-console-output.log', allowEmptyArchive: true
            sh """
                curl -k -u ${JENKINS_READ_USR}:${JENKINS_READ_PSW} -o archive.zip ${BUILD_URL}artifact/*zip*/archive.zip
                oci --region us-phoenix-1 os object put --force --namespace ${OCI_OS_NAMESPACE} -bn ${OCI_OS_ARTIFACT_BUCKET} --name ${env.JOB_NAME}/${env.BRANCH_NAME}/${env.BUILD_NUMBER}/archive.zip --file archive.zip
                rm archive.zip
            """
        }
        cleanup {
            deleteDir()
        }
    }
}

def runGinkgo(testSuitePath, kubeConfig = '') {
    catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
        sh """
            if [ ! -z "${kubeConfig}" ]; then
                export KUBECONFIG="${kubeConfig}"
            fi
            cd ${GO_REPO_PATH}/verrazzano/tests/e2e
            if [ -d "${testSuitePath}" ]; then
                ginkgo -vv --progress --keep-going --no-color ${GINKGO_REPORT_ARGS} -tags="${params.TAGGED_TESTS}" --focus-file="${params.INCLUDED_TESTS}" --skip-file="${params.EXCLUDED_TESTS}" ${testSuitePath}/...
            fi
        """
    }
}

def runGinkgoWorkloadCluster(testSuitePath,dumpDir='') {
    catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
        sh """
            if [ ! -z "${dumpDir}" ]; then
                export DUMP_DIRECTORY=${dumpDir}
            fi
            cd ${GO_REPO_PATH}/verrazzano/tests/e2e
            TS=\$(date +%Y%m%d%H%M%S%N)
            TEMPKUBECONFIGPATH=/tmp/${CLUSTER_NAME}-kubeconfig-\$TS
            kubectl get secret -n ${CLUSTER_NAME} ${CLUSTER_NAME}-kubeconfig -o json | jq -r '.data.value' | base64 -d > \$TEMPKUBECONFIGPATH
            export KUBECONFIG=\$TEMPKUBECONFIGPATH
            ginkgo -v -keep-going --no-color ${GINKGO_REPORT_ARGS} -tags="${params.TAGGED_TESTS}" --focus-file="${params.INCLUDED_TESTS}" --skip-file="${params.EXCLUDED_TESTS}" ${testSuitePath}/...
            unset KUBECONFIG
            rm -rf \$TEMPKUBECONFIGPATH
        """
    }
}

def runGinkgoRandomizeWorkloadCluster(testSuitePath,dumpDir='') {
    catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
        sh """
            if [ ! -z "${dumpDir}" ]; then
                export DUMP_DIRECTORY=${dumpDir}
            fi
            TS=\$(date +%Y%m%d%H%M%S%N)
            TEMPKUBECONFIGPATH=/tmp/${CLUSTER_NAME}-kubeconfig-\$TS
            kubectl get secret -n ${CLUSTER_NAME} ${CLUSTER_NAME}-kubeconfig -o json | jq -r '.data.value' | base64 -d > \$TEMPKUBECONFIGPATH
            export KUBECONFIG=\$TEMPKUBECONFIGPATH
            cd ${GO_REPO_PATH}/verrazzano/tests/e2e
            if [ -d "${testSuitePath}" ]; then
                ginkgo -p --randomize-all -v --keep-going --no-color ${GINKGO_REPORT_ARGS} -tags="${params.TAGGED_TESTS}" --focus-file="${params.INCLUDED_TESTS}" --skip-file="${params.EXCLUDED_TESTS}" ${testSuitePath}/...
            fi
            unset KUBECONFIG
            rm -rf \$TEMPKUBECONFIGPATH
        """
    }
}

def runGinkgoAppTestWorkloadCluster(testSuitePath, namespace, dumpDir='', skipDeploy='false', skipUndeploy='false', component='', appConfig='') {
    catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
        sh """
            if [ ! -z "${dumpDir}" ]; then
                export DUMP_DIRECTORY=${dumpDir}
            fi
            TS=\$(date +%Y%m%d%H%M%S%N)
            TEMPKUBECONFIGPATH=/tmp/${CLUSTER_NAME}-kubeconfig-\$TS
            kubectl get secret -n ${CLUSTER_NAME} ${CLUSTER_NAME}-kubeconfig -o json | jq -r '.data.value' | base64 -d > \$TEMPKUBECONFIGPATH
            export KUBECONFIG=\$TEMPKUBECONFIGPATH
            cd ${GO_REPO_PATH}/verrazzano/tests/e2e
            ginkgo -v --keep-going --no-color ${GINKGO_REPORT_ARGS} -tags="${params.TAGGED_TESTS}" --focus-file="${params.INCLUDED_TESTS}" --skip-file="${params.EXCLUDED_TESTS}" ${testSuitePath}/... -- --skipDeploy=${skipDeploy} --skipUndeploy=${skipUndeploy} --namespace=${namespace}
            unset KUBECONFIG
            rm -rf \$TEMPKUBECONFIGPATH
        """
    }
}


def saveConsoleScreenShots() {
    sh "$GO_REPO_PATH/verrazzano/ci/scripts/save_console_test_artifacts.sh"
}


// Called in parallel Stage console of Stage Run Acceptance Tests
def acceptanceTestsConsole(dumpRoot) {
    catchError(buildResult: 'SUCCESS', stageResult: 'FAILURE') {
        try {
            sh "CONSOLE_REPO_BRANCH=${params.CONSOLE_REPO_BRANCH} $GO_REPO_PATH/verrazzano/ci/scripts/run_console_tests.sh"
        } catch (err) {
            saveConsoleScreenShots()
            error "${err}"
        }
    }
}


def generateVerifyInstallStages(dumpRoot) {
    return [
        "verify-install keycloak": {
            runGinkgoRandomizeWorkloadCluster('verify-install/keycloak',"${dumpRoot}/verify-install-keycloak")
        },
        "verify-install kubernetes": {
            runGinkgoRandomizeWorkloadCluster('verify-install/kubernetes',"${dumpRoot}/verify-install-kubernetes")
        },
        "verify-install istio": {
            runGinkgoRandomizeWorkloadCluster('verify-install/istio',"${dumpRoot}/verify-install-istio")
        },
        "verify-install kiali": {
            runGinkgoRandomizeWorkloadCluster('verify-install/kiali',"${dumpRoot}/verify-install-kiali")
        },
        "verify-install verrazzano": {
            runGinkgoRandomizeWorkloadCluster('verify-install/verrazzano',"${dumpRoot}/verify-install-verrazzano")
        },
        "verify-install web": {
            runGinkgoRandomizeWorkloadCluster('verify-install/web',"${dumpRoot}/verify-install-web")
        },
        "verify-install clusteragent": {
            runGinkgoRandomizeWorkloadCluster('verify-install/clusteragent',"${dumpRoot}/verify-install-clusteragent")
        },
        "verify-install clusterapi": {
            runGinkgoRandomizeWorkloadCluster('verify-install/clusterapi',"${dumpRoot}/verify-install-clusterapi")
        },
        "verify-install thanos": {
            runGinkgoRandomizeWorkloadCluster('verify-install/thanos',"${dumpRoot}/verify-install-thanos")
        },
         "verify-install security": {
            runGinkgoRandomizeWorkloadCluster('verify-install/security',"${dumpRoot}/verify-install-security")
        },
         "verify-install velero": {
            runGinkgoRandomizeWorkloadCluster('verify-install/velero',"${dumpRoot}/verify-install-velero")
        },
         "verify-install validators": {
            runGinkgoRandomizeWorkloadCluster('verify-install/validators',"${dumpRoot}/verify-install-validators")
        },
    ]
}

def generateVerifyInfraStages(dumpRoot) {
    return [
        "verify-scripts": {
            runGinkgoWorkloadCluster('scripts')
        },
        "verify-infra oam": {
            runGinkgoRandomizeWorkloadCluster('verify-infra/oam', "${dumpRoot}/verify-infra-oam")
        },
        "verify-infra restapi": {
            runGinkgoRandomizeWorkloadCluster('verify-infra/restapi', "${dumpRoot}/verify-infra-restapi")
        },
        "verify-infra vmi": {
            runGinkgoRandomizeWorkloadCluster('verify-infra/vmi', "${dumpRoot}/verify-infra-vmi")
        },
        "system component metrics": {
            runGinkgoRandomizeWorkloadCluster('metrics/syscomponents', "${dumpRoot}/system-component-metrics")
        },
        "system logging": {
            runGinkgoRandomizeWorkloadCluster('logging/system', "${dumpRoot}/system-logging")
        },
    ]
}

def generateAllAcceptanceTestStages(dumpRoot, skipDeploy='false', skipUndeploy='false') {
    return generateSecurityTests(dumpRoot) +
        generateNonWLSTests(dumpRoot, skipDeploy, skipUndeploy) +
        generateWLSTests(dumpRoot, skipDeploy, skipUndeploy)
}

def generateSecurityTests(dumpRoot) {
    return [
        "istio authorization policy": {
            runGinkgoWorkloadCluster('istio/authz', "${dumpRoot}/istio-authz-policy")
        },
        "security rbac": {
            runGinkgoWorkloadCluster('security/rbac', "${dumpRoot}/sec-role-based-access")
        },
        "security network policies": {
            if (params.CREATE_CLUSTER_USE_CALICO == true) {
                runGinkgoWorkloadCluster('security/netpol', "${dumpRoot}/netpol")
            } else {
                echo "[INFO] Calico not enabled, skipping network policies tests"
            }
        },
    ]
}

def generateNonWLSTests(dumpRoot, skipDeploy='false', skipUndeploy='false') {
    return [
        "deployment metrics": {
            runGinkgoWorkloadCluster('metrics/deploymetrics', "${dumpRoot}/k8sdeploy-workload-metrics")
        },
        "examples logging helidon": {
            runGinkgoWorkloadCluster('logging/helidon', "${dumpRoot}/examples-logging-helidon")
        },
        "examples springboot": {
            runGinkgoAppTestWorkloadCluster('examples/springboot', "springboot", "${dumpRoot}/examples-spring", skipDeploy, skipUndeploy)
        },
        "examples helidon": {
            runGinkgoAppTestWorkloadCluster('examples/helidon', "hello-helidon", "${dumpRoot}/examples-helidon", skipDeploy, skipUndeploy)
        },
        "examples helidon-config": {
            runGinkgoAppTestWorkloadCluster('examples/helidonconfig', "helidon-config", "${dumpRoot}/examples-helidon-config", skipDeploy, skipUndeploy)
        },

        "istio authorization policy": {
            runGinkgoWorkloadCluster('istio/authz', "${dumpRoot}/istio-authz-policy")
        },

        "security network policies": {
            runGinkgoWorkloadCluster('security/netpol', "${dumpRoot}/netpol")
        },

        "examples helidon service template": {
            runGinkgoAppTestWorkloadCluster('examples/helidon', 'hello-helidon-service-template', "${dumpRoot}/examples-helidon-service-template", 'false', 'false', 'examples/hello-helidon/hello-helidon-comp-service-template.yaml', 'examples/hello-helidon/hello-helidon-app-custom-port.yaml')
        },

        "examples helidon manualscalertait": {
            runGinkgoAppTestWorkloadCluster('examples/helidon', 'examples-helidon-manualscalertait', "${dumpRoot}/examples-helidon-manualscalertait", 'false', 'false','examples/hello-helidon/hello-helidon-comp.yaml', 'examples/hello-helidon/hello-helidon-app-scaler-trait.yaml')
        },

       "jaeger helidon": {
            runGinkgoWorkloadCluster('jaeger/helidon', "${dumpRoot}/jaeger-helidon")
        },
        "jaeger system": {
            runGinkgoWorkloadCluster('jaeger/system', "${dumpRoot}/jaeger-system")
        },
    ]
}

def generateWLSTests(dumpRoot, skipDeploy='false', skipUndeploy='false') {
    return [
        "weblogic workload": {
            runGinkgoAppTestWorkloadCluster('workloads/weblogic', "hello-wls", "${dumpRoot}/weblogic-workload", skipDeploy, skipUndeploy)
        },
        "coherence workload": {
            runGinkgoAppTestWorkloadCluster('workloads/coherence', "hello-coherence", "${dumpRoot}/coherence-workload", skipDeploy, skipUndeploy)
        },
        "console ingress": {
            // doesn't work with the deployment hooks
            runGinkgoWorkloadCluster('ingress/console', "wls-console")
        },
    ]
}

def set_capi_variables() {
   int OCNE_CP_COUNT = params.CONTROL_PLANE_MACHINE_COUNT.toInteger()
   env.CONTROL_PLANE_MACHINE_COUNT =  OCNE_CP_COUNT
   int OCNE_WORKERS_COUNT = params.NODE_MACHINE_COUNT.toInteger()
   env.NODE_MACHINE_COUNT =  OCNE_WORKERS_COUNT

   env.VPO_IMAGE = sh(returnStdout: true, script: "cat \${WORKSPACE}/acceptance-test-operator.yaml | grep image: | grep ghcr | head -1 | awk '{print \$2}' | cut -d: -f1").trim()
   env.VPO_TAG = sh(returnStdout: true, script: "cat \${WORKSPACE}/acceptance-test-operator.yaml | grep image: | grep ghcr | head -1 | awk '{print \$2}' | cut -d: -f2-").trim()
   println("VPO Image is ${env.VPO_IMAGE}, VPO Tag is ${env.VPO_TAG}")
}

def ensureVZCleanupFromWorkloadCluster() {
    sh """
        TS=\$(date +%Y%m%d%H%M%S%N)
        TEMPKUBECONFIGPATH=/tmp/${CLUSTER_NAME}-kubeconfig-\$TS
        kubectl get secret -n ${CLUSTER_NAME} ${CLUSTER_NAME}-kubeconfig -o json | jq -r '.data.value' | base64 -d > \$TEMPKUBECONFIGPATH
        kubectl --kubeconfig \$TEMPKUBECONFIGPATH delete vz --all --timeout=10m
        rm -rf \$TEMPKUBECONFIGPATH
    """
}

def ensureCAPICleanup() {
    sh """
        kubectl delete cl -n ${CLUSTER_NAME} ${CLUSTER_NAME}
        kubectl delete ns ${CLUSTER_NAME}
    """
}


def dumpK8sCluster(dumpDirectory) {
    sh """
        ${GO_REPO_PATH}/verrazzano/ci/scripts/capture_cluster_snapshot.sh ${dumpDirectory}
    """
}

def dumpOCNECluster(dumpDirectory) {
    sh """
        TS=\$(date +%Y%m%d%H%M%S%N)
        TEMPKUBECONFIGPATH=/tmp/${CLUSTER_NAME}-kubeconfig-\$TS
        kubectl get secret -n ${CLUSTER_NAME} ${CLUSTER_NAME}-kubeconfig -o json | jq -r '.data.value' | base64 -d > \$TEMPKUBECONFIGPATH
        export KUBECONFIG=\$TEMPKUBECONFIGPATH
        ${GO_REPO_PATH}/verrazzano/ci/scripts/capture_cluster_snapshot.sh ${dumpDirectory}
        unset KUBECONFIG
        rm -rf \$TEMPKUBECONFIGPATH
    """
}


def dumpVerrazzanoSystemPods() {
    sh """
        cd ${GO_REPO_PATH}/verrazzano/platform-operator
        export DIAGNOSTIC_LOG="${VERRAZZANO_INSTALL_LOGS_DIR}/verrazzano-system-pods.log"
        ./scripts/install/k8s-dump-objects.sh -o pods -n verrazzano-system -m "verrazzano system pods" || echo "failed" > ${POST_DUMP_FAILED_FILE}
        export DIAGNOSTIC_LOG="${VERRAZZANO_INSTALL_LOGS_DIR}/verrazzano-system-certs.log"
        ./scripts/install/k8s-dump-objects.sh -o cert -n verrazzano-system -m "verrazzano system certs" || echo "failed" > ${POST_DUMP_FAILED_FILE}
        export DIAGNOSTIC_LOG="${VERRAZZANO_INSTALL_LOGS_DIR}/verrazzano-system-osd.log"
        ./scripts/install/k8s-dump-objects.sh -o pods -n verrazzano-system -r "vmi-system-osd-*" -m "verrazzano system opensearchdashboards log" -l -c osd || echo "failed" > ${POST_DUMP_FAILED_FILE}
        export DIAGNOSTIC_LOG="${VERRAZZANO_INSTALL_LOGS_DIR}/verrazzano-system-es-master.log"
        ./scripts/install/k8s-dump-objects.sh -o pods -n verrazzano-system -r "vmi-system-es-master-*" -m "verrazzano system opensearchdashboards log" -l -c es-master || echo "failed" > ${POST_DUMP_FAILED_FILE}
    """
}

def dumpCattleSystemPods() {
    sh """
        cd ${GO_REPO_PATH}/verrazzano/platform-operator
        export DIAGNOSTIC_LOG="${VERRAZZANO_INSTALL_LOGS_DIR}/cattle-system-pods.log"
        ./scripts/install/k8s-dump-objects.sh -o pods -n cattle-system -m "cattle system pods" || echo "failed" > ${POST_DUMP_FAILED_FILE}
        export DIAGNOSTIC_LOG="${VERRAZZANO_INSTALL_LOGS_DIR}/rancher.log"
        ./scripts/install/k8s-dump-objects.sh -o pods -n cattle-system -r "rancher-*" -m "Rancher logs" -c rancher -l || echo "failed" > ${POST_DUMP_FAILED_FILE}
    """
}

def dumpNginxIngressControllerLogs() {
    sh """
        cd ${GO_REPO_PATH}/verrazzano/platform-operator
        export DIAGNOSTIC_LOG="${VERRAZZANO_INSTALL_LOGS_DIR}/nginx-ingress-controller.log"
        ./scripts/install/k8s-dump-objects.sh -o pods -n ingress-nginx -r "nginx-ingress-controller-*" -m "Nginx Ingress Controller" -c controller -l || echo "failed" > ${POST_DUMP_FAILED_FILE}
    """
}

def dumpVerrazzanoPlatformOperatorLogs() {
    sh """
        ## dump out verrazzano-platform-operator logs
        mkdir -p ${WORKSPACE}/verrazzano-platform-operator/logs
        kubectl -n verrazzano-install logs --selector=app=verrazzano-platform-operator > ${WORKSPACE}/verrazzano-platform-operator/logs/verrazzano-platform-operator-pod.log --tail -1 || echo "failed" > ${POST_DUMP_FAILED_FILE}
        kubectl -n verrazzano-install describe pod --selector=app=verrazzano-platform-operator > ${WORKSPACE}/verrazzano-platform-operator/logs/verrazzano-platform-operator-pod.out || echo "failed" > ${POST_DUMP_FAILED_FILE}
        echo "verrazzano-platform-operator logs dumped to verrazzano-platform-operator-pod.log"
        echo "verrazzano-platform-operator pod description dumped to verrazzano-platform-operator-pod.out"
        echo "------------------------------------------"
    """
}

def dumpVerrazzanoApplicationOperatorLogs() {
    sh """
        ## dump out verrazzano-application-operator logs
        mkdir -p ${WORKSPACE}/verrazzano-application-operator/logs
        kubectl -n verrazzano-system logs --selector=app=verrazzano-application-operator > ${WORKSPACE}/verrazzano-application-operator/logs/verrazzano-application-operator-pod.log --tail -1 || echo "failed" > ${POST_DUMP_FAILED_FILE}
        kubectl -n verrazzano-system describe pod --selector=app=verrazzano-application-operator > ${WORKSPACE}/verrazzano-application-operator/logs/verrazzano-application-operator-pod.out || echo "failed" > ${POST_DUMP_FAILED_FILE}
        echo "verrazzano-application-operator logs dumped to verrazzano-application-operator-pod.log"
        echo "verrazzano-application-operator pod description dumped to verrazzano-application-operator-pod.out"
        echo "------------------------------------------"
    """
}

def dumpOamKubernetesRuntimeLogs() {
    sh """
        ## dump out oam-kubernetes-runtime logs
        mkdir -p ${WORKSPACE}/oam-kubernetes-runtime/logs
        kubectl -n verrazzano-system logs --selector=app.kubernetes.io/instance=oam-kubernetes-runtime > ${WORKSPACE}/oam-kubernetes-runtime/logs/oam-kubernetes-runtime-pod.log --tail -1 || echo "failed" > ${POST_DUMP_FAILED_FILE}
        kubectl -n verrazzano-system describe pod --selector=app.kubernetes.io/instance=oam-kubernetes-runtime > ${WORKSPACE}/verrazzano-application-operator/logs/oam-kubernetes-runtime-pod.out || echo "failed" > ${POST_DUMP_FAILED_FILE}
        echo "verrazzano-application-operator logs dumped to oam-kubernetes-runtime-pod.log"
        echo "verrazzano-application-operator pod description dumped to oam-kubernetes-runtime-pod.out"
        echo "------------------------------------------"
    """
}

def dumpVerrazzanoApiLogs() {
    sh """
        cd ${GO_REPO_PATH}/verrazzano/platform-operator
        export DIAGNOSTIC_LOG="${VERRAZZANO_INSTALL_LOGS_DIR}/verrazzano-authproxy.log"
        ./scripts/install/k8s-dump-objects.sh -o pods -n verrazzano-system -r "verrazzano-authproxy-*" -m "verrazzano api" -c verrazzano-authproxy -l || echo "failed" > ${POST_DUMP_FAILED_FILE}
    """
}

def getEffectiveDumpOnSuccess() {
    def effectiveValue = params.DUMP_K8S_CLUSTER_ON_SUCCESS
    if (FORCE_DUMP_K8S_CLUSTER_ON_SUCCESS.equals("true") && (env.BRANCH_NAME.equals("master"))) {
        effectiveValue = true
        echo "Forcing dump on success based on global override setting"
    }
    return effectiveValue
}

def deleteCluster() {
    sh """
        cd ${GO_REPO_PATH}/verrazzano/platform-operator
        make delete-cluster
        if [ -f ${POST_DUMP_FAILED_FILE} ]; then
          echo "Failures seen during dumping of artifacts, treat post as failed"
          exit 1
        fi
    """
}

def setDisplayName() {
    echo "Start setDisplayName"
    def causes = currentBuild.getBuildCauses()
    echo "causes: " + causes.toString()
    for (cause in causes) {
        def causeString = cause.toString()
        echo "current cause: " + causeString
        if (causeString.contains("UpstreamCause") && causeString.contains("Started by upstream project")) {
             echo "This job was caused by " + causeString
             if (causeString.contains("verrazzano-periodic-triggered-tests")) {
                 currentBuild.displayName = env.BUILD_NUMBER + " : PERIODIC"
             } else if (causeString.contains("verrazzano-flaky-tests")) {
                 currentBuild.displayName = env.BUILD_NUMBER + " : FLAKY"
             }
         }
    }
    echo "End setDisplayName"
}

def dumpCAPIPODLogs() {
    sh """
        ## dump out capi pod logs
        mkdir -p ${WORKSPACE}/capi-kubernetes-runtime/logs
        kubectl -n verrazzano-capi logs -l cluster.x-k8s.io/provider=cluster-api > ${WORKSPACE}/capi-kubernetes-runtime/logs/capi-controller-manager-pod.log --tail -1 || echo "failed" > ${POST_DUMP_FAILED_FILE}
        kubectl -n verrazzano-capi logs -l cluster.x-k8s.io/provider=bootstrap-ocne > ${WORKSPACE}/capi-kubernetes-runtime/logs/capi-ocne-bootstrap-controller-manager-pod.log --tail -1 || echo "failed" > ${POST_DUMP_FAILED_FILE}
        kubectl -n verrazzano-capi logs -l cluster.x-k8s.io/provider=control-plane-ocne > ${WORKSPACE}/capi-kubernetes-runtime/logs/capi-ocne-control-plane-controller-manager-pod.log --tail -1 || echo "failed" > ${POST_DUMP_FAILED_FILE}
        kubectl -n verrazzano-capi logs -l cluster.x-k8s.io/provider=infrastructure-oci > ${WORKSPACE}/capi-kubernetes-runtime/logs/capoci-controller-manager-pod.log --tail -1 || echo "failed" > ${POST_DUMP_FAILED_FILE}
        kubectl -n verrazzano-system logs -l app=verrazzano-cluster-operator > ${WORKSPACE}/capi-kubernetes-runtime/logs/verrazzano-cluster-operator.log --tail -1 || echo "failed" > ${POST_DUMP_FAILED_FILE}
        kubectl -n verrazzano-capi describe pod -l cluster.x-k8s.io/provider=cluster-api > ${WORKSPACE}/capi-kubernetes-runtime/logs/capi-controller-manager-pod.out || echo "failed" > ${POST_DUMP_FAILED_FILE}
        kubectl -n verrazzano-capi describe pod -l cluster.x-k8s.io/provider=bootstrap-ocne > ${WORKSPACE}/capi-kubernetes-runtime/logs/capi-ocne-bootstrap-controller-manager-pod.out || echo "failed" > ${POST_DUMP_FAILED_FILE}
        kubectl -n verrazzano-capi describe pod -l cluster.x-k8s.io/provider=control-plane-ocne > ${WORKSPACE}/capi-kubernetes-runtime/logs/ccapi-ocne-control-plane-controller-manager-pod.out || echo "failed" > ${POST_DUMP_FAILED_FILE}
        kubectl -n verrazzano-capi describe pod -l cluster.x-k8s.io/provider=infrastructure-oci > ${WORKSPACE}/capi-kubernetes-runtime/logs/capoci-controller-manager-pod.out || echo "failed" > ${POST_DUMP_FAILED_FILE}
        echo "capi logs logs dumped successfully"
        echo "capi pod description dumped successfully"
        echo "------------------------------------------"
    """
}

def dumpCAPIClusterDetails() {
    sh """
        ## dump out capi conditions
        mkdir -p ${WORKSPACE}/capi-conditions/logs
        clusterctl describe cluster -n ${CLUSTER_NAMESPACE} ${CLUSTER_NAMESPACE} --grouping=false --echo --show-conditions all --show-templates --show-resourcesets  --show-machinesets > ${WORKSPACE}/capi-conditions/logs/capi-cluster-conditions.out || echo "failed" > ${POST_DUMP_FAILED_FILE}
        echo "capi cluster conditions dumped successfully to capi-cluster-conditions.out"
        echo "------------------------------------------"
    """
}
